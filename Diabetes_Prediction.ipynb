{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5815330f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m StandardScaler\n\u001b[1;32m      5\u001b[0m diabetes_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mdiabetes_prediction_dataset.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "diabetes_data = pd.read_csv('diabetes_prediction_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3640da32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Phase One: Data Preparation\n",
    "\n",
    "\n",
    "# Removing records with invalid Glucose values\n",
    "diabetes_data = diabetes_data[(diabetes_data['age'] >= 5) & (diabetes_data['age'] <= 90)]\n",
    "\n",
    "# Dropping duplicate rows\n",
    "diabetes_data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Dropping rows with missing values (NaN)\n",
    "diabetes_data.dropna(inplace=True)\n",
    "\n",
    "columns_to_remove = ['gender', 'smoking_history']\n",
    "diabetes_data = diabetes_data.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd26611",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_one_records = diabetes_data[diabetes_data['diabetes'] == 1]\n",
    "\n",
    "num_records = 12600 \n",
    "diabetes_zero_records = diabetes_data[diabetes_data['diabetes'] == 0].sample(n=num_records, random_state=42)\n",
    "\n",
    "\n",
    "filtered_diabetes_data = pd.concat([diabetes_one_records, diabetes_zero_records])\n",
    "\n",
    "filtered_diabetes_data.to_csv('filtered_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5212e9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.09%\n"
     ]
    }
   ],
   "source": [
    "#describe input and output\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, lr=0.01, n_iters=1000):\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.random.randn(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.n_iters):\n",
    "            linear_pred = np.dot(X, self.weights) + self.bias\n",
    "            predictions = sigmoid(linear_pred)\n",
    "\n",
    "            dw = (1 / n_samples) * np.dot(X.T, (predictions - y))\n",
    "            db = (1 / n_samples) * np.sum(predictions - y)\n",
    "\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_pred = np.dot(X, self.weights) + self.bias\n",
    "        y_pred = sigmoid(linear_pred)\n",
    "        class_pred = [1 if y > 0.5 else 0 for y in y_pred]\n",
    "        return class_pred\n",
    "\n",
    "\n",
    "# Splitting the data into inputs (X) and output (y)\n",
    "X = filtered_diabetes_data.drop(columns=['diabetes'])\n",
    "y = filtered_diabetes_data['diabetes']\n",
    "\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "train_size = int(0.8 * len(filtered_diabetes_data))  # 80% for training\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.28 )\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "def accuracy(y_pred_scaled, y_test):\n",
    "    return np.sum(y_pred_scaled==y_test)/len(y_test)\n",
    "\n",
    "acc = accuracy(y_pred_scaled, y_test)\n",
    "print(\"Accuracy: {:.2f}%\".format(acc*100) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e305fd4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of predicting on new inputs\n",
    "new_inputs = pd.DataFrame({\n",
    "    'age': [80],\n",
    "    'hypertension': [1],\n",
    "    'heart_disease' : [1],\n",
    "    'bmi' : [95],\n",
    "    'HbA1c_level': [9],\n",
    "    'blood_glucose_level': [300]\n",
    "})\n",
    "\n",
    "model.predict(new_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68192b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "filename = 'finalized_model.sav'\n",
    "\n",
    "file = open(filename, 'wb')\n",
    "\n",
    "pickle.dump(model, file)\n",
    "\n",
    "file.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
